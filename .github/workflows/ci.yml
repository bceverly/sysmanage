name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

permissions:
  contents: read

jobs:
  test-backend:
    name: Backend Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow writing to update README badge
      pull-requests: write  # Allow creating pull requests

    strategy:
      fail-fast: false  # Continue testing other versions even if one fails
      matrix:
        python-version: ['3.10', '3.11', '3.12', '3.13']
        # Python 3.10 included for Ubuntu 22.04 LTS compatibility

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: abc123
          POSTGRES_USER: sysmanage
          POSTGRES_DB: sysmanage
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v6

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v6
      with:
        python-version: ${{ matrix.python-version }}
        allow-prereleases: true  # Allow testing on pre-release Python versions

    - name: Cache pip packages
      uses: actions/cache@v5
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio

    - name: Create test config
      run: |
        sudo mkdir -p /etc
        sudo tee /etc/sysmanage.yaml > /dev/null <<EOF
        api:
          host: "localhost"
          port: 8000
          certFile: ""
          chainFile: ""
          keyFile: ""
        database:
          user: "sysmanage"
          password: "abc123"
          host: "localhost"
          port: 5432
          name: "sysmanage"
        security:
          password_salt: "TEST_fBLqXrh6evnpiDOEA+TtFy1c4ItzVIyyMUsYhCraqLs="
          admin_userid: "admin@sysmanage.org"
          admin_password: "TEST_AdminPass123!"
          jwt_secret: "TEST_SuCHjkous8e0OgHRPxZ1Uayz0NS0b0SGXUXS26MUaZU="
          jwt_algorithm: "HS256"
          jwt_auth_timeout: 6000
          jwt_refresh_timeout: 60000
        webui:
          host: "localhost"
          port: 7443
        EOF

    - name: Run backend database migrations
      run: |
        python -c "from alembic.config import Config; from alembic import command; cfg = Config('alembic.ini'); command.upgrade(cfg, 'head')"
      env:
        PYTHONPATH: .
        DATABASE_URL: postgresql://sysmanage:abc123@localhost:5432/sysmanage

    - name: Run backend tests
      run: |
        # Clean old test databases
        find . -name "*.db" -type f -delete 2>/dev/null || true
        find /tmp -name "*sysmanage*.db" -type f -delete 2>/dev/null || true
        find /tmp -name "tmp*.db" -type f -delete 2>/dev/null || true

        # Run Python tests (excluding UI tests)
        python -m pytest tests/ --ignore=tests/ui/ -v --tb=short --cov=backend --cov-report=term-missing --cov-report=html --cov-report=xml
      env:
        PYTHONPATH: .
        DATABASE_URL: postgresql://sysmanage:abc123@localhost:5432/sysmanage

    - name: Extract coverage percentage
      id: coverage
      run: |
        COVERAGE=$(python -c "
        import xml.etree.ElementTree as ET
        tree = ET.parse('coverage.xml')
        root = tree.getroot()
        coverage = float(root.attrib['line-rate']) * 100
        print(f'{coverage:.0f}')
        ")
        echo "percentage=$COVERAGE" >> $GITHUB_OUTPUT
        echo "Coverage: $COVERAGE%"

        # Determine color based on coverage
        if [ $COVERAGE -ge 90 ]; then
          COLOR="brightgreen"
        elif [ $COVERAGE -ge 80 ]; then
          COLOR="green"
        elif [ $COVERAGE -ge 70 ]; then
          COLOR="yellowgreen"
        elif [ $COVERAGE -ge 60 ]; then
          COLOR="yellow"
        elif [ $COVERAGE -ge 40 ]; then
          COLOR="orange"
        else
          COLOR="red"
        fi
        echo "color=$COLOR" >> $GITHUB_OUTPUT
        echo "Badge color: $COLOR"

    - name: Save backend coverage data
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo '${{ steps.coverage.outputs.percentage }}' > backend-coverage.txt
        echo '${{ steps.coverage.outputs.color }}' > backend-color.txt

    - name: Upload backend coverage data
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/upload-artifact@v6
      with:
        name: backend-coverage-data-py${{ matrix.python-version }}
        path: |
          backend-coverage.txt
          backend-color.txt

    - name: Checkout repository for backend badge update
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/checkout@v6
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Update backend coverage badge
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        # Update backend coverage badge
        sed -i "s/backend%20test%20coverage-[0-9]*%25-[a-z]*/backend%20test%20coverage-${{ steps.coverage.outputs.percentage }}%25-${{ steps.coverage.outputs.color }}/g" README.md
        # Also fix the broken badge if it exists
        sed -i "s/backend%20test%20coverage-%25-\.svg/backend%20test%20coverage-${{ steps.coverage.outputs.percentage }}%25-${{ steps.coverage.outputs.color }}.svg/g" README.md

    - name: Create PR for backend coverage badge
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      id: backend-pr
      uses: peter-evans/create-pull-request@v8
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}
        commit-message: "Update backend test coverage badge to ${{ steps.coverage.outputs.percentage }}% [skip ci]"
        title: "Update backend coverage badge to ${{ steps.coverage.outputs.percentage }}%"
        body: |
          ðŸ”§ **Backend Test Coverage Update**

          - **Coverage**: ${{ steps.coverage.outputs.percentage }}%
          - **Badge Color**: ${{ steps.coverage.outputs.color }}

          Generated automatically by CI pipeline.
        branch: update-backend-coverage-badge-${{ github.run_number }}
        delete-branch: true

    - name: Enable auto-merge for backend coverage PR
      if: github.ref == 'refs/heads/main' && github.event_name == 'push' && steps.backend-pr.outputs.pull-request-number
      run: |
        gh pr merge ${{ steps.backend-pr.outputs.pull-request-number }} --auto --squash
      env:
        GITHUB_TOKEN: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Upload backend coverage to Codecov
      uses: codecov/codecov-action@v5
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        files: ./coverage.xml
        flags: backend
        name: backend-coverage

  lint-backend:
    name: Backend Linting
    runs-on: ubuntu-latest
    permissions:
      contents: read
    
    steps:
    - uses: actions/checkout@v6

    - name: Set up Python 3.12
      uses: actions/setup-python@v6
      with:
        python-version: '3.12'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pylint black==26.1.0 bandit

    - name: Run Black formatter check
      run: |
        python -m black --check --diff backend/ tests/

    - name: Run Pylint
      run: |
        python -m pylint backend/ --rcfile=.pylintrc --exit-zero

    - name: Run Bandit security scan
      run: |
        python -m bandit -r backend/ -f screen -x backend/tests/
        # Also generate JSON report for artifacts
        python -m bandit -r backend/ -f json -x backend/tests/ -o bandit-report.json || true
    
    - name: Upload Bandit results
      uses: actions/upload-artifact@v6
      with:
        name: bandit-security-report
        path: bandit-report.json

  test-frontend:
    name: Frontend Tests
    runs-on: ubuntu-latest
    needs: [test-backend, lint-backend]  # Only run after backend tests pass
    permissions:
      contents: write  # Allow writing to update README badge
      pull-requests: write  # Allow creating pull requests

    steps:
    - uses: actions/checkout@v6

    - name: Set up Node.js
      uses: actions/setup-node@v6
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Create test config for frontend
      run: |
        sudo mkdir -p /etc
        sudo tee /etc/sysmanage.yaml > /dev/null <<EOF
        api:
          host: "localhost"
          port: 8000
          certFile: ""
          chainFile: ""
          keyFile: ""
        database:
          user: "sysmanage"
          password: "abc123"
          host: "localhost"
          port: 5432
          name: "sysmanage"
        security:
          password_salt: "TEST_fBLqXrh6evnpiDOEA+TtFy1c4ItzVIyyMUsYhCraqLs="
          admin_userid: "admin@sysmanage.org"
          admin_password: "TEST_AdminPass123!"
          jwt_secret: "TEST_SuCHjkous8e0OgHRPxZ1Uayz0NS0b0SGXUXS26MUaZU="
          jwt_algorithm: "HS256"
          jwt_auth_timeout: 6000
          jwt_refresh_timeout: 60000
        webui:
          host: "localhost"
          port: 7443
        EOF

    - name: Install frontend dependencies
      working-directory: frontend
      run: |
        npm cache clean --force || true
        npm install --legacy-peer-deps || npm ci --legacy-peer-deps

    - name: Run security audit
      working-directory: frontend
      run: |
        # Run audit and save results
        npm audit --audit-level=high --json > npm-audit-ci.json || true
        npm audit --audit-level=high || true
    
    - name: Upload npm audit results
      uses: actions/upload-artifact@v6
      with:
        name: npm-audit-ci-report
        path: frontend/npm-audit-ci.json

    - name: Run frontend linting
      working-directory: frontend
      run: npm run lint

    - name: Run frontend tests with coverage
      working-directory: frontend
      run: |
        npm run test:coverage

    - name: Debug coverage files
      working-directory: frontend
      run: |
        echo "ðŸ” Debugging coverage file structure:"
        echo "Current directory: $(pwd)"
        echo "Coverage directory exists: $(test -d coverage && echo 'YES' || echo 'NO')"
        if [ -d coverage ]; then
          echo "Coverage directory contents:"
          ls -la coverage/ || echo "Failed to list coverage directory"
          echo "Looking for specific files:"
          echo "coverage-summary.json exists: $(test -f coverage/coverage-summary.json && echo 'YES' || echo 'NO')"
          echo "index.html exists: $(test -f coverage/index.html && echo 'YES' || echo 'NO')"
          echo "src/mocks directory exists: $(test -d coverage/src/mocks && echo 'YES' || echo 'NO')"
          if [ -d coverage/src ]; then
            echo "Coverage src subdirectories:"
            ls -la coverage/src/
          fi
        fi

    - name: Extract frontend coverage percentage
      id: frontend-coverage
      working-directory: frontend
      run: |
        # Extract coverage from JSON report (more reliable than parsing text output)
        if [ -f "coverage/coverage-summary.json" ]; then
          COVERAGE=$(python3 -c 'import json; f=open("coverage/coverage-summary.json"); data=json.load(f); print(int(data["total"]["lines"]["pct"]))')
        else
          echo "No coverage report found, using 0"
          COVERAGE=0
        fi

        echo "percentage=$COVERAGE" >> $GITHUB_OUTPUT
        echo "Frontend Coverage: $COVERAGE%"

        # Determine color based on coverage
        if [ $COVERAGE -ge 90 ]; then
          COLOR="brightgreen"
        elif [ $COVERAGE -ge 80 ]; then
          COLOR="green"
        elif [ $COVERAGE -ge 70 ]; then
          COLOR="yellowgreen"
        elif [ $COVERAGE -ge 60 ]; then
          COLOR="yellow"
        elif [ $COVERAGE -ge 40 ]; then
          COLOR="orange"
        else
          COLOR="red"
        fi
        echo "color=$COLOR" >> $GITHUB_OUTPUT
        echo "Frontend Badge color: $COLOR"

    - name: Checkout repository for frontend badge update
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/checkout@v6
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Update frontend coverage badge
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        # Update frontend coverage badge
        sed -i "s/frontend%20test%20coverage-[0-9]*%25-[a-z]*/frontend%20test%20coverage-${{ steps.frontend-coverage.outputs.percentage }}%25-${{ steps.frontend-coverage.outputs.color }}/g" README.md
        # Also fix the broken badge if it exists
        sed -i "s/frontend%20test%20coverage-%25-\.svg/frontend%20test%20coverage-${{ steps.frontend-coverage.outputs.percentage }}%25-${{ steps.frontend-coverage.outputs.color }}.svg/g" README.md

    - name: Create PR for frontend coverage badge
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      id: frontend-pr
      uses: peter-evans/create-pull-request@v8
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}
        commit-message: "Update frontend test coverage badge to ${{ steps.frontend-coverage.outputs.percentage }}% [skip ci]"
        title: "Update frontend coverage badge to ${{ steps.frontend-coverage.outputs.percentage }}%"
        body: |
          ðŸ”§ **Frontend Test Coverage Update**

          - **Coverage**: ${{ steps.frontend-coverage.outputs.percentage }}%
          - **Badge Color**: ${{ steps.frontend-coverage.outputs.color }}

          Generated automatically by CI pipeline.
        branch: update-frontend-coverage-badge-${{ github.run_number }}
        delete-branch: true

    - name: Enable auto-merge for frontend coverage PR
      if: github.ref == 'refs/heads/main' && github.event_name == 'push' && steps.frontend-pr.outputs.pull-request-number
      run: |
        gh pr merge ${{ steps.frontend-pr.outputs.pull-request-number }} --auto --squash
      env:
        GITHUB_TOKEN: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Upload frontend coverage to Codecov
      uses: codecov/codecov-action@v5
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        directory: ./frontend/coverage
        flags: frontend
        name: frontend-coverage

    - name: Check if coverage exists before upload
      working-directory: frontend
      run: |
        echo "ðŸ” Final coverage check before artifact upload:"
        if [ -d "coverage" ]; then
          echo "âœ… Coverage directory exists"
          echo "Files in coverage directory:"
          find coverage -type f | head -10
          echo "Coverage directory size: $(du -sh coverage/ | cut -f1)"
          echo "COVERAGE_EXISTS=true" >> $GITHUB_ENV
        else
          echo "âŒ No coverage directory found for artifacts"
          echo "COVERAGE_EXISTS=false" >> $GITHUB_ENV
        fi

    - name: Upload MSW test artifacts
      uses: actions/upload-artifact@v6
      if: always()
      with:
        name: msw-test-coverage-${{ github.run_number }}
        path: frontend/coverage/
        if-no-files-found: warn
        retention-days: 7

    - name: Report artifact upload status
      if: always()
      run: |
        if [ "${{ env.COVERAGE_EXISTS }}" = "true" ]; then
          echo "âœ… Coverage files should have been uploaded as artifacts"
        else
          echo "âŒ No coverage files found - check test execution above"
        fi

  build:
    name: Build Check
    runs-on: ubuntu-latest
    permissions:
      contents: read
    needs: [test-frontend]  # Only run after frontend tests pass

    steps:
    - uses: actions/checkout@v6

    - name: Set up Node.js
      uses: actions/setup-node@v6
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Create test config for build
      run: |
        sudo mkdir -p /etc
        sudo tee /etc/sysmanage.yaml > /dev/null <<EOF
        api:
          host: "localhost"
          port: 8000
          certFile: ""
          chainFile: ""
          keyFile: ""
        database:
          user: "sysmanage"
          password: "abc123"
          host: "localhost"
          port: 5432
          name: "sysmanage"
        security:
          password_salt: "TEST_fBLqXrh6evnpiDOEA+TtFy1c4ItzVIyyMUsYhCraqLs="
          admin_userid: "admin@sysmanage.org"
          admin_password: "TEST_AdminPass123!"
          jwt_secret: "TEST_SuCHjkous8e0OgHRPxZ1Uayz0NS0b0SGXUXS26MUaZU="
          jwt_algorithm: "HS256"
          jwt_auth_timeout: 6000
          jwt_refresh_timeout: 60000
        webui:
          host: "localhost"
          port: 7443
        EOF

    - name: Install frontend dependencies
      working-directory: frontend
      run: |
        npm cache clean --force || true
        npm install --legacy-peer-deps || npm ci --legacy-peer-deps

    - name: Build frontend
      working-directory: frontend
      run: npm run build

    - name: Upload build artifacts
      uses: actions/upload-artifact@v6
      with:
        name: frontend-build
        path: frontend/dist/

  ui-tests:
    name: UI Tests
    runs-on: ubuntu-latest
    permissions:
      contents: read
    needs: [build]  # Only run after build succeeds
    # Only run if all previous tests passed
    if: success()

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: sysmanage
          POSTGRES_USER: sysmanage
          POSTGRES_PASSWORD: abc123
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v6

    - name: Set up Python 3.12
      uses: actions/setup-python@v6
      with:
        python-version: '3.12'

    - name: Set up Node.js
      uses: actions/setup-node@v6
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Cache pip packages
      uses: actions/cache@v5
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install frontend dependencies
      working-directory: frontend
      run: |
        npm cache clean --force || true
        npm install --legacy-peer-deps || npm ci --legacy-peer-deps

    - name: Install Playwright and browsers
      run: |
        # First install playwright package if not already installed
        pip install playwright

        # Then install browsers
        python -m playwright install --with-deps chromium firefox

        # Install additional system dependencies for UI testing
        sudo apt-get update
        sudo apt-get install -y libnss3 libatk-bridge2.0-0 libdrm2 libxkbcommon0 libgtk-3-0

    - name: Create test config
      run: |
        sudo mkdir -p /etc
        sudo tee /etc/sysmanage.yaml > /dev/null <<EOF
        api:
          host: "0.0.0.0"
          port: 8080
          certFile: ""
          chainFile: ""
          keyFile: ""
        database:
          user: "sysmanage"
          password: "abc123"
          host: "localhost"
          port: 5432
          name: "sysmanage"
        security:
          password_salt: "TEST_fBLqXrh6evnpiDOEA+TtFy1c4ItzVIyyMUsYhCraqLs="
          admin_userid: "admin@sysmanage.org"
          admin_password: "TEST_AdminPass123!"
          jwt_secret: "TEST_SuCHjkous8e0OgHRPxZ1Uayz0NS0b0SGXUXS26MUaZU="
          jwt_algorithm: "HS256"
          jwt_auth_timeout: 6000
          jwt_refresh_timeout: 60000
        webui:
          host: "0.0.0.0"
          port: 3000
        vault:
          enabled: false
        EOF

    - name: Run backend database migrations
      run: |
        python -c "from alembic.config import Config; from alembic import command; cfg = Config('alembic.ini'); command.upgrade(cfg, 'head')"
      env:
        PYTHONPATH: .
        DATABASE_URL: postgresql://sysmanage:abc123@localhost:5432/sysmanage

    - name: Build frontend
      working-directory: frontend
      run: npm run build

    - name: Verify database connection
      run: |
        echo "ðŸ” Verifying database connection..."
        PGPASSWORD=abc123 psql -h localhost -U sysmanage -d sysmanage -c "SELECT 1;" || {
          echo "âŒ Database connection failed!"
          exit 1
        }
        echo "âœ… Database connection successful"

    - name: Start backend server
      run: |
        echo "ðŸš€ Starting backend server..."

        # Check if the backend directory and main.py exist
        ls -la backend/
        if [ ! -f "backend/main.py" ]; then
          echo "âŒ backend/main.py not found!"
          exit 1
        fi

        # Show current working directory and config
        echo "Current directory: $(pwd)"
        echo "Config file exists: $(test -f /etc/sysmanage.yaml && echo 'YES' || echo 'NO')"

        # Start backend with output to log file for debugging
        cd backend
        echo "Starting uvicorn from directory: $(pwd)"
        echo "PYTHONPATH will be: .."
        PYTHONPATH=.. python -m uvicorn main:app --host 0.0.0.0 --port 8080 > /tmp/backend.log 2>&1 &
        BACKEND_PID=$!
        echo $BACKEND_PID > /tmp/backend.pid
        echo "Backend started with PID: $BACKEND_PID"

        # Give server time to start
        sleep 15

        # Check if process is still running
        if ! kill -0 $BACKEND_PID 2>/dev/null; then
          echo "âŒ Backend process died! Log contents:"
          cat /tmp/backend.log
          exit 1
        fi

        echo "âœ… Backend server started successfully"
      env:
        PYTHONPATH: .

    - name: Start frontend server
      working-directory: frontend
      run: |
        npx serve -s dist -l 3000 &
        echo $! > /tmp/frontend.pid
        sleep 5

    - name: Wait for servers to be ready
      run: |
        echo "Waiting for backend health check..."
        if ! timeout 60 bash -c 'until curl -f http://localhost:8080/api/health; do echo "Waiting for backend..."; sleep 2; done'; then
          echo "âŒ Backend health check failed! Backend logs:"
          cat /tmp/backend.log || echo "No backend log file found"
          echo "Backend process status:"
          if [ -f /tmp/backend.pid ]; then
            PID=$(cat /tmp/backend.pid)
            if kill -0 $PID 2>/dev/null; then
              echo "Backend process $PID is still running"
            else
              echo "Backend process $PID is not running"
            fi
          fi
          echo "Port 8080 status:"
          netstat -tulpn | grep :8080 || echo "Nothing listening on port 8080"
          exit 1
        fi
        echo "âœ… Backend is ready"

        echo "Waiting for frontend..."
        if ! timeout 60 bash -c 'until curl -f http://localhost:3000/; do echo "Waiting for frontend..."; sleep 2; done'; then
          echo "âŒ Frontend health check failed!"
          echo "Port 3000 status:"
          netstat -tulpn | grep :3000 || echo "Nothing listening on port 3000"
          exit 1
        fi
        echo "âœ… Frontend is ready"

    - name: Run Playwright UI tests
      id: ui-tests
      run: |
        echo "ðŸŽ­ Running Playwright UI tests..."
        if PYTHONPATH=tests/ui:$PYTHONPATH python -m pytest tests/ui/test_login_cross_browser.py tests/ui/test_hosts_playwright.py tests/ui/test_updates_playwright.py --confcutdir=tests/ui -p conftest_playwright -v --tb=short; then
          echo "status=passing" >> $GITHUB_OUTPUT
          echo "color=brightgreen" >> $GITHUB_OUTPUT
          echo "âœ… All UI tests passed"
        else
          echo "status=failing" >> $GITHUB_OUTPUT
          echo "color=red" >> $GITHUB_OUTPUT
          echo "âŒ UI tests failed"
          exit 1
        fi
      env:
        CI: true

    - name: Upload UI test artifacts on failure
      uses: actions/upload-artifact@v6
      if: failure()
      with:
        name: ui-test-results-${{ github.run_number }}
        path: |
          /tmp/claude/login_failure_*.png
          tests/ui/test-results/
        retention-days: 7

    - name: Save UI test status data
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo '${{ steps.ui-tests.outputs.status }}' > ui-test-status.txt
        echo '${{ steps.ui-tests.outputs.color }}' > ui-test-color.txt

    - name: Upload UI test status data
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/upload-artifact@v6
      with:
        name: ui-test-status-data
        path: |
          ui-test-status.txt
          ui-test-color.txt

    - name: Checkout repository for UI badge update
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/checkout@v6
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Update UI tests badge
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        # Update UI tests badge
        sed -i "s/ui%20tests-[a-z]*-[a-z]*/ui%20tests-${{ steps.ui-tests.outputs.status }}-${{ steps.ui-tests.outputs.color }}/g" README.md
        # Also fix the broken badge if it exists
        sed -i "s/ui%20tests--\.svg/ui%20tests-${{ steps.ui-tests.outputs.status }}-${{ steps.ui-tests.outputs.color }}.svg/g" README.md

    - name: Create PR for UI tests badge
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      id: ui-tests-pr
      uses: peter-evans/create-pull-request@v8
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}
        commit-message: "Update UI tests badge to ${{ steps.ui-tests.outputs.status }} [skip ci]"
        title: "Update UI tests badge to ${{ steps.ui-tests.outputs.status }}"
        body: |
          ðŸŽ­ **UI Tests Status Update**

          - **Status**: ${{ steps.ui-tests.outputs.status }}
          - **Badge Color**: ${{ steps.ui-tests.outputs.color }}

          Generated automatically by CI pipeline.
        branch: update-ui-tests-badge-${{ github.run_number }}
        delete-branch: true

    - name: Enable auto-merge for UI tests badge PR
      if: github.ref == 'refs/heads/main' && github.event_name == 'push' && steps.ui-tests-pr.outputs.pull-request-number
      run: |
        gh pr merge ${{ steps.ui-tests-pr.outputs.pull-request-number }} --auto --squash
      env:
        GITHUB_TOKEN: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Stop servers
      if: always()
      run: |
        echo "ðŸ›‘ Stopping servers..."
        if [ -f /tmp/backend.pid ]; then
          kill $(cat /tmp/backend.pid) || true
        fi
        if [ -f /tmp/frontend.pid ]; then
          kill $(cat /tmp/frontend.pid) || true
        fi
        pkill -f "uvicorn" || true
        pkill -f "serve" || true

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow writing to update README badge
      pull-requests: write  # Allow creating pull requests
    needs: [ui-tests]  # Only run after UI tests pass
    if: success()

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: sysmanage
          POSTGRES_USER: sysmanage
          POSTGRES_PASSWORD: abc123
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v6

    - name: Set up Python 3.12
      uses: actions/setup-python@v6
      with:
        python-version: '3.12'

    - name: Set up Node.js
      uses: actions/setup-node@v6
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Cache pip packages
      uses: actions/cache@v5
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install frontend dependencies
      working-directory: frontend
      run: |
        npm cache clean --force || true
        npm install --legacy-peer-deps || npm ci --legacy-peer-deps

    - name: Install Artillery for load testing
      run: |
        npm install -g artillery@latest

    - name: Install Playwright and browsers
      run: |
        pip install playwright
        python -m playwright install --with-deps chromium firefox

    - name: Create test config
      run: |
        sudo mkdir -p /etc
        sudo tee /etc/sysmanage.yaml > /dev/null <<EOF
        api:
          host: "0.0.0.0"
          port: 8001
          certFile: ""
          chainFile: ""
          keyFile: ""
        database:
          user: "sysmanage"
          password: "abc123"
          host: "localhost"
          port: 5432
          name: "sysmanage"
        security:
          password_salt: "TEST_fBLqXrh6evnpiDOEA+TtFy1c4ItzVIyyMUsYhCraqLs="
          admin_userid: "admin@sysmanage.org"
          admin_password: "TEST_AdminPass123!"
          jwt_secret: "TEST_SuCHjkous8e0OgHRPxZ1Uayz0NS0b0SGXUXS26MUaZU="
          jwt_algorithm: "HS256"
          jwt_auth_timeout: 6000
          jwt_refresh_timeout: 60000
        webui:
          host: "0.0.0.0"
          port: 3001
        vault:
          enabled: false
        EOF

    - name: Run backend database migrations
      run: |
        python -c "from alembic.config import Config; from alembic import command; cfg = Config('alembic.ini'); command.upgrade(cfg, 'head')"
      env:
        PYTHONPATH: .
        DATABASE_URL: postgresql://sysmanage:abc123@localhost:5432/sysmanage

    - name: Build frontend
      working-directory: frontend
      run: npm run build

    - name: Start backend server for performance testing
      run: |
        echo "ðŸš€ Starting backend server on port 8001 for performance testing..."
        cd backend
        PYTHONPATH=.. python -m uvicorn main:app --host 0.0.0.0 --port 8001 > /tmp/backend-perf.log 2>&1 &
        BACKEND_PID=$!
        echo $BACKEND_PID > /tmp/backend-perf.pid
        echo "Backend started with PID: $BACKEND_PID"

        # Give server time to start
        sleep 15

        # Check if process is still running
        if ! kill -0 $BACKEND_PID 2>/dev/null; then
          echo "âŒ Backend process died! Log contents:"
          cat /tmp/backend-perf.log
          exit 1
        fi

        echo "âœ… Backend server started successfully for performance testing"
      env:
        PYTHONPATH: .

    - name: Start frontend server for performance testing
      working-directory: frontend
      run: |
        npx serve -s dist -l 3001 &
        echo $! > /tmp/frontend-perf.pid
        sleep 5

    - name: Wait for servers to be ready
      run: |
        echo "Waiting for backend health check..."
        if ! timeout 60 bash -c 'until curl -f http://localhost:8001/api/health; do echo "Waiting for backend..."; sleep 2; done'; then
          echo "âŒ Backend health check failed!"
          cat /tmp/backend-perf.log || echo "No backend log file found"
          exit 1
        fi
        echo "âœ… Backend is ready"

        echo "Waiting for frontend..."
        if ! timeout 60 bash -c 'until curl -f http://localhost:3001/; do echo "Waiting for frontend..."; sleep 2; done'; then
          echo "âŒ Frontend health check failed!"
          exit 1
        fi
        echo "âœ… Frontend is ready"

    - name: Create Artillery configuration
      run: |
        cat > artillery.yml << EOF
        config:
          target: 'http://localhost:8001'
          phases:
            - duration: 60
              arrivalRate: 10
              name: 'Warm up'
            - duration: 120
              arrivalRate: 25
              name: 'Sustained load'
        scenarios:
          - name: 'API Health Check Load Test'
            weight: 40
            flow:
              - get:
                  url: '/api/health'
          - name: 'API Authentication Load Test'
            weight: 30
            flow:
              - post:
                  url: '/api/auth/login'
                  json:
                    username: 'admin@sysmanage.org'
                    password: 'TEST_AdminPass123!'
          - name: 'Static Asset Load Test'
            weight: 30
            flow:
              - get:
                  url: 'http://localhost:3001/'
        EOF

    - name: Run Artillery load tests
      id: artillery-tests
      run: |
        echo "ðŸŽ¯ Running Artillery load tests..."

        if artillery run artillery.yml --output artillery-report.json; then
          echo "âœ… Artillery load tests completed successfully"

          # Extract key metrics from the report
          if [ -f artillery-report.json ]; then
            # Parse Artillery results
            REQUESTS_TOTAL=$(python3 -c "
            import json
            with open('artillery-report.json', 'r') as f:
                data = json.load(f)
            total = data.get('aggregate', {}).get('counters', {}).get('http.requests', 0)
            print(total)
            " 2>/dev/null || echo "0")

            RESPONSE_TIME_P95=$(python3 -c "
            import json
            with open('artillery-report.json', 'r') as f:
                data = json.load(f)
            p95 = data.get('aggregate', {}).get('summaries', {}).get('http.response_time', {}).get('p95', 0)
            print(int(p95))
            " 2>/dev/null || echo "0")

            ERROR_RATE=$(python3 -c "
            import json
            with open('artillery-report.json', 'r') as f:
                data = json.load(f)
            errors = data.get('aggregate', {}).get('counters', {}).get('errors.ECONNREFUSED', 0)
            errors += data.get('aggregate', {}).get('counters', {}).get('http.codes.500', 0)
            total = data.get('aggregate', {}).get('counters', {}).get('http.requests', 1)
            rate = round((errors / total) * 100, 1) if total > 0 else 0
            print(rate)
            " 2>/dev/null || echo "0")

            echo "ðŸ“Š Artillery Results:"
            echo "   Total Requests: $REQUESTS_TOTAL"
            echo "   95th Percentile Response Time: ${RESPONSE_TIME_P95}ms"
            echo "   Error Rate: ${ERROR_RATE}%"

            # Determine status and color
            if [ "$ERROR_RATE" = "0" ] && [ "$RESPONSE_TIME_P95" -lt 1000 ]; then
              echo "artillery_status=excellent" >> $GITHUB_OUTPUT
              echo "artillery_color=brightgreen" >> $GITHUB_OUTPUT
              echo "artillery_metric=${RESPONSE_TIME_P95}ms" >> $GITHUB_OUTPUT
            elif [ "$ERROR_RATE" = "0" ] && [ "$RESPONSE_TIME_P95" -lt 2000 ]; then
              echo "artillery_status=good" >> $GITHUB_OUTPUT
              echo "artillery_color=green" >> $GITHUB_OUTPUT
              echo "artillery_metric=${RESPONSE_TIME_P95}ms" >> $GITHUB_OUTPUT
            elif [ "$ERROR_RATE" = "0" ] && [ "$RESPONSE_TIME_P95" -lt 5000 ]; then
              echo "artillery_status=acceptable" >> $GITHUB_OUTPUT
              echo "artillery_color=yellow" >> $GITHUB_OUTPUT
              echo "artillery_metric=${RESPONSE_TIME_P95}ms" >> $GITHUB_OUTPUT
            else
              echo "artillery_status=poor" >> $GITHUB_OUTPUT
              echo "artillery_color=red" >> $GITHUB_OUTPUT
              echo "artillery_metric=${ERROR_RATE}%25%20errors" >> $GITHUB_OUTPUT
            fi

            # Generate HTML report
            artillery report artillery-report.json --output artillery-report.html
            echo "ðŸ“‹ Artillery HTML report generated: artillery-report.html"
          else
            echo "artillery_status=no--data" >> $GITHUB_OUTPUT
            echo "artillery_color=lightgrey" >> $GITHUB_OUTPUT
            echo "artillery_metric=unknown" >> $GITHUB_OUTPUT
          fi
        else
          echo "âŒ Artillery load tests failed"
          echo "artillery_status=failed" >> $GITHUB_OUTPUT
          echo "artillery_color=red" >> $GITHUB_OUTPUT
          echo "artillery_metric=failed" >> $GITHUB_OUTPUT
        fi

    - name: Run Playwright performance tests
      id: playwright-perf-tests
      run: |
        echo "ðŸŽ­ Running Playwright performance tests..."

        # Create a basic Playwright performance test file if it doesn't exist
        mkdir -p tests/ui
        if [ ! -f tests/ui/test_performance_playwright.py ]; then
          cat > tests/ui/test_performance_playwright.py << 'EOF'
        import pytest
        from playwright.async_api import Page, expect
        import time

        @pytest.mark.asyncio
        async def test_page_load_performance(page: Page, ui_config, start_server):
            """Test page load performance metrics"""
            try:
                start_time = time.time()
                await page.goto(f"{ui_config.base_url}/", wait_until="networkidle")
                load_time = (time.time() - start_time) * 1000

                # Get performance metrics
                metrics = await page.evaluate("""
                () => {
                    const navigation = performance.getEntriesByType('navigation')[0];
                    const paintEntries = performance.getEntriesByType('paint');

                    return {
                        domContentLoaded: navigation ? navigation.domContentLoadedEventEnd - navigation.domContentLoadedEventStart : 0,
                        firstContentfulPaint: paintEntries.find(entry => entry.name === 'first-contentful-paint')?.startTime || 0,
                        loadComplete: navigation ? navigation.loadEventEnd - navigation.loadEventStart : 0
                    };
                }
                """)

                print(f"Page Load Time: {load_time:.0f}ms")
                print(f"DOM Content Loaded: {metrics['domContentLoaded']:.0f}ms")
                print(f"First Contentful Paint: {metrics['firstContentfulPaint']:.0f}ms")

                # Performance assertions
                assert load_time < 10000, f"Page load took too long: {load_time}ms"
                assert metrics['firstContentfulPaint'] < 5000, f"FCP too slow: {metrics['firstContentfulPaint']}ms"

                return {
                    'load_time': load_time,
                    'fcp': metrics['firstContentfulPaint'],
                    'dcl': metrics['domContentLoaded']
                }

            except Exception as e:
                print(f"Performance test failed: {e}")
                raise
        EOF
        fi

        if PYTHONPATH=tests/ui:$PYTHONPATH python -m pytest tests/ui/test_performance_playwright.py --confcutdir=tests/ui -p conftest_playwright -v --tb=short; then
          echo "âœ… Playwright performance tests completed successfully"
          echo "playwright_status=passing" >> $GITHUB_OUTPUT
          echo "playwright_color=brightgreen" >> $GITHUB_OUTPUT
          echo "playwright_metric=optimized" >> $GITHUB_OUTPUT
        else
          echo "âŒ Playwright performance tests failed"
          echo "playwright_status=failing" >> $GITHUB_OUTPUT
          echo "playwright_color=red" >> $GITHUB_OUTPUT
          echo "playwright_metric=issues" >> $GITHUB_OUTPUT
        fi

    - name: Upload performance test artifacts
      uses: actions/upload-artifact@v6
      if: always()
      with:
        name: performance-test-results-${{ github.run_number }}
        path: |
          artillery-report.json
          artillery-report.html
        retention-days: 7

    - name: Save performance test status data
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        echo '${{ steps.artillery-tests.outputs.artillery_status }}' > artillery-status.txt
        echo '${{ steps.artillery-tests.outputs.artillery_color }}' > artillery-color.txt
        echo '${{ steps.artillery-tests.outputs.artillery_metric }}' > artillery-metric.txt
        echo '${{ steps.playwright-perf-tests.outputs.playwright_status }}' > playwright-perf-status.txt
        echo '${{ steps.playwright-perf-tests.outputs.playwright_color }}' > playwright-perf-color.txt
        echo '${{ steps.playwright-perf-tests.outputs.playwright_metric }}' > playwright-perf-metric.txt

    - name: Upload performance test status data
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/upload-artifact@v6
      with:
        name: performance-test-status-data
        path: |
          artillery-status.txt
          artillery-color.txt
          artillery-metric.txt
          playwright-perf-status.txt
          playwright-perf-color.txt
          playwright-perf-metric.txt

    - name: Checkout repository for performance badge update
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      uses: actions/checkout@v6
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Update performance badges
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      run: |
        # Update Performance Tests badge
        sed -i "s/performance%20tests-[^-]*-[a-z]*/performance%20tests-${{ steps.playwright-perf-tests.outputs.playwright_metric }}-${{ steps.playwright-perf-tests.outputs.playwright_color }}/g" README.md

        # Update Artillery Load Tests badge
        sed -i "s/artillery-[^-]*-[a-z]*/artillery-${{ steps.artillery-tests.outputs.artillery_metric }}-${{ steps.artillery-tests.outputs.artillery_color }}/g" README.md

    - name: Create PR for performance badges
      if: github.ref == 'refs/heads/main' && github.event_name == 'push'
      id: performance-pr
      uses: peter-evans/create-pull-request@v8
      with:
        token: ${{ secrets.AUTO_MERGE_TOKEN }}
        commit-message: "Update performance test badges [skip ci]"
        title: "Update performance test badges"
        body: |
          ðŸš€ **Performance Test Results Update**

          ## Artillery Load Tests
          - **Status**: ${{ steps.artillery-tests.outputs.artillery_status }}
          - **Metric**: ${{ steps.artillery-tests.outputs.artillery_metric }}
          - **Badge Color**: ${{ steps.artillery-tests.outputs.artillery_color }}

          ## Playwright Performance Tests
          - **Status**: ${{ steps.playwright-perf-tests.outputs.playwright_status }}
          - **Metric**: ${{ steps.playwright-perf-tests.outputs.playwright_metric }}
          - **Badge Color**: ${{ steps.playwright-perf-tests.outputs.playwright_color }}

          Generated automatically by CI pipeline.
        branch: update-performance-badges-${{ github.run_number }}
        delete-branch: true

    - name: Enable auto-merge for performance badges PR
      if: github.ref == 'refs/heads/main' && github.event_name == 'push' && steps.performance-pr.outputs.pull-request-number
      run: |
        gh pr merge ${{ steps.performance-pr.outputs.pull-request-number }} --auto --squash
      env:
        GITHUB_TOKEN: ${{ secrets.AUTO_MERGE_TOKEN }}

    - name: Stop performance test servers
      if: always()
      run: |
        echo "ðŸ›‘ Stopping performance test servers..."
        if [ -f /tmp/backend-perf.pid ]; then
          kill $(cat /tmp/backend-perf.pid) || true
        fi
        if [ -f /tmp/frontend-perf.pid ]; then
          kill $(cat /tmp/frontend-perf.pid) || true
        fi
        pkill -f "uvicorn.*8001" || true
        pkill -f "serve.*3001" || true

  # Job 7: SonarCloud Analysis (runs after all other jobs succeed)
  sonarcloud:
    name: SonarCloud Code Analysis
    runs-on: ubuntu-latest
    needs: [test-backend, lint-backend, test-frontend, build, ui-tests, performance-tests]  # Only runs when all jobs succeed
    permissions:
      contents: read

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: abc123
          POSTGRES_USER: sysmanage
          POSTGRES_DB: sysmanage
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v6
      with:
        fetch-depth: 0  # Shallow clones should be disabled for better analysis

    - name: Set up Python 3.12
      uses: actions/setup-python@v6
      with:
        python-version: '3.12'

    - name: Set up Node.js
      uses: actions/setup-node@v6
      with:
        node-version: '20'
        registry-url: 'https://registry.npmjs.org/'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Cache pip packages
      uses: actions/cache@v5
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-3.12-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-3.12-
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio

    - name: Install frontend dependencies
      working-directory: frontend
      run: |
        npm cache clean --force || true
        npm install --legacy-peer-deps || npm ci --legacy-peer-deps

    - name: Create test config
      run: |
        sudo mkdir -p /etc
        sudo tee /etc/sysmanage.yaml > /dev/null <<EOF
        api:
          host: "localhost"
          port: 8000
          certFile: ""
          chainFile: ""
          keyFile: ""
        database:
          user: "sysmanage"
          password: "abc123"
          host: "localhost"
          port: 5432
          name: "sysmanage"
        security:
          password_salt: "TEST_fBLqXrh6evnpiDOEA+TtFy1c4ItzVIyyMUsYhCraqLs="
          admin_userid: "admin@sysmanage.org"
          admin_password: "TEST_AdminPass123!"
          jwt_secret: "TEST_SuCHjkous8e0OgHRPxZ1Uayz0NS0b0SGXUXS26MUaZU="
          jwt_algorithm: "HS256"
          jwt_auth_timeout: 6000
          jwt_refresh_timeout: 60000
        webui:
          host: "localhost"
          port: 7443
        EOF

    - name: Run backend database migrations
      run: |
        python -c "from alembic.config import Config; from alembic import command; cfg = Config('alembic.ini'); command.upgrade(cfg, 'head')"
      env:
        PYTHONPATH: .
        DATABASE_URL: postgresql://sysmanage:abc123@localhost:5432/sysmanage

    - name: Run backend tests with coverage
      run: |
        # Clean old test databases
        find . -name "*.db" -type f -delete 2>/dev/null || true
        find /tmp -name "*sysmanage*.db" -type f -delete 2>/dev/null || true
        find /tmp -name "tmp*.db" -type f -delete 2>/dev/null || true

        # Run Python tests (excluding UI tests) with coverage
        python -m pytest tests/ --ignore=tests/ui/ -v --tb=short --cov=backend --cov-report=xml --cov-report=term-missing
      env:
        PYTHONPATH: .
        DATABASE_URL: postgresql://sysmanage:abc123@localhost:5432/sysmanage

    - name: Run frontend tests with coverage
      working-directory: frontend
      run: |
        npm run test:coverage

    - name: Cache SonarCloud packages
      uses: actions/cache@v5
      with:
        path: ~/.sonar/cache
        key: ${{ runner.os }}-sonar
        restore-keys: ${{ runner.os }}-sonar

    - name: SonarCloud Scan
      uses: SonarSource/sonarqube-scan-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Needed to get PR information
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

    - name: SonarCloud summary
      if: success()
      run: |
        echo "================================================"
        echo "âœ… SONARCLOUD ANALYSIS COMPLETE!"
        echo "================================================"
        echo ""
        echo "âœ“ Backend analysis: SUCCESS"
        echo "âœ“ Frontend analysis: SUCCESS"
        echo "âœ“ Coverage uploaded: SUCCESS"
        echo ""
        echo "View full analysis results at:"
        echo "https://sonarcloud.io/project/overview?id=bceverly_sysmanage"
        echo ""