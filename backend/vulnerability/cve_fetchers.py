"""
CVE Data Fetchers.

Implements fetching CVE data from various sources:
- NVD (National Vulnerability Database)
- Ubuntu Security API
- Debian Security Tracker
- Red Hat Security Data API
- Microsoft Security Response Center
- FreeBSD VuXML
"""

import asyncio
import logging
import defusedxml.ElementTree as ET  # nosec B405 - using defusedxml for safe XML parsing
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, Optional

import httpx
from sqlalchemy.orm import Session, sessionmaker

from backend.persistence import db as db_module
from backend.persistence.models import (
    PackageVulnerability,
    Vulnerability,
)

from .cve_sources import CVE_SOURCES, CveRefreshError

logger = logging.getLogger(__name__)

# Constants
UTC_TIMEZONE_OFFSET = "+00:00"


class SeverityConverter:
    """Helper methods for converting severity scores/priorities."""

    @staticmethod
    def cvss2_to_severity(score: float) -> str:
        """Convert CVSS v2 score to severity string."""
        if score >= 7.0:
            return "HIGH"
        if score >= 4.0:
            return "MEDIUM"
        if score > 0:
            return "LOW"
        return "NONE"

    @staticmethod
    def cvss3_to_severity(score: float) -> str:
        """Convert CVSS v3.x score to severity string."""
        if score >= 9.0:
            return "CRITICAL"
        if score >= 7.0:
            return "HIGH"
        if score >= 4.0:
            return "MEDIUM"
        if score > 0:
            return "LOW"
        return "NONE"

    @staticmethod
    def ubuntu_priority_to_severity(priority: str) -> str:
        """Convert Ubuntu priority to severity string."""
        priority_map = {
            "critical": "CRITICAL",
            "high": "HIGH",
            "medium": "MEDIUM",
            "low": "LOW",
            "negligible": "NONE",
            "unknown": "NONE",
        }
        return priority_map.get(priority.lower(), "NONE")

    @staticmethod
    def debian_urgency_to_severity(urgency: str) -> str:
        """Convert Debian urgency to severity string."""
        urgency_map = {
            "unimportant": "NONE",
            "low": "LOW",
            "medium": "MEDIUM",
            "high": "HIGH",
            "not yet assigned": "NONE",
        }
        return urgency_map.get(urgency.lower(), "NONE")


class CveFetchers(SeverityConverter):
    """
    Mixin class providing CVE fetching methods for various data sources.

    Requires the parent class to provide:
    - _get_http_client() -> httpx.AsyncClient
    """

    async def _get_http_client(self) -> httpx.AsyncClient:
        """Must be implemented by parent class."""
        raise NotImplementedError

    async def fetch_nvd_data(
        self, db: Session, api_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Fetch CVE data from NVD.

        Args:
            db: Database session
            api_key: Optional NVD API key for higher rate limits

        Returns:
            Dictionary with fetch results
        """
        client = await self._get_http_client()
        base_url = CVE_SOURCES["nvd"]["base_url"]
        vulnerabilities_processed = 0
        packages_processed = 0

        # Calculate date range (fetch last 7 days of modified CVEs)
        end_date = datetime.now(timezone.utc)
        start_date = end_date - timedelta(days=7)

        # Format dates with proper timezone offset for NVD API
        date_format = f"%Y-%m-%dT%H:%M:%S.000{UTC_TIMEZONE_OFFSET}"
        start_date_str = start_date.strftime(date_format)
        end_date_str = end_date.strftime(date_format)

        logger.info("NVD fetch date range: %s to %s", start_date_str, end_date_str)

        params = {
            "lastModStartDate": start_date_str,
            "lastModEndDate": end_date_str,
            "resultsPerPage": 500,
            "startIndex": 0,
        }

        headers = {}
        if api_key:
            headers["apiKey"] = api_key

        try:
            max_pages = 100
            page_count = 0

            while page_count < max_pages:
                page_count += 1
                logger.info(
                    "NVD fetch page %d, startIndex=%d",
                    page_count,
                    params["startIndex"],
                )

                response = await client.get(base_url, params=params, headers=headers)
                response.raise_for_status()
                data = response.json()

                cves = data.get("vulnerabilities", [])
                if not cves:
                    logger.info("NVD fetch complete - no more CVEs")
                    break

                for cve_item in cves:
                    cve_data = cve_item.get("cve", {})
                    cve_id = cve_data.get("id")
                    if not cve_id:
                        continue

                    # Extract CVSS score and severity
                    cvss_score = None
                    cvss_version = None
                    severity = "NONE"

                    metrics = cve_data.get("metrics", {})
                    if "cvssMetricV31" in metrics:
                        cvss_data = metrics["cvssMetricV31"][0]["cvssData"]
                        cvss_score = str(cvss_data.get("baseScore", ""))
                        cvss_version = "3.1"
                        severity = cvss_data.get("baseSeverity", "NONE")
                    elif "cvssMetricV30" in metrics:
                        cvss_data = metrics["cvssMetricV30"][0]["cvssData"]
                        cvss_score = str(cvss_data.get("baseScore", ""))
                        cvss_version = "3.0"
                        severity = cvss_data.get("baseSeverity", "NONE")
                    elif "cvssMetricV2" in metrics:
                        cvss_data = metrics["cvssMetricV2"][0]["cvssData"]
                        cvss_score = str(cvss_data.get("baseScore", ""))
                        cvss_version = "2.0"
                        severity = self.cvss2_to_severity(cvss_data.get("baseScore", 0))

                    # Extract description
                    descriptions = cve_data.get("descriptions", [])
                    description = ""
                    for desc in descriptions:
                        if desc.get("lang") == "en":
                            description = desc.get("value", "")
                            break

                    # Extract published/modified dates
                    published_date = None
                    modified_date = None
                    if cve_data.get("published"):
                        published_date = datetime.fromisoformat(
                            cve_data["published"].replace("Z", UTC_TIMEZONE_OFFSET)
                        ).replace(tzinfo=None)
                    if cve_data.get("lastModified"):
                        modified_date = datetime.fromisoformat(
                            cve_data["lastModified"].replace("Z", UTC_TIMEZONE_OFFSET)
                        ).replace(tzinfo=None)

                    # Extract references
                    references = []
                    for ref in cve_data.get("references", []):
                        references.append(ref.get("url"))

                    # Upsert vulnerability
                    vuln = (
                        db.query(Vulnerability)
                        .filter(Vulnerability.cve_id == cve_id)
                        .first()
                    )
                    if vuln:
                        vuln.description = description
                        vuln.cvss_score = cvss_score
                        vuln.cvss_version = cvss_version
                        vuln.severity = severity
                        vuln.published_date = published_date
                        vuln.modified_date = modified_date
                        vuln.references = references
                    else:
                        vuln = Vulnerability(
                            cve_id=cve_id,
                            description=description,
                            cvss_score=cvss_score,
                            cvss_version=cvss_version,
                            severity=severity,
                            published_date=published_date,
                            modified_date=modified_date,
                            references=references,
                        )
                        db.add(vuln)

                    vulnerabilities_processed += 1

                db.commit()

                # Check if there are more results
                total_results = data.get("totalResults", 0)
                params["startIndex"] += len(cves)

                logger.info(
                    "NVD processed %d CVEs, total so far: %d, total available: %d",
                    len(cves),
                    params["startIndex"],
                    total_results,
                )

                if params["startIndex"] >= total_results:
                    logger.info("NVD fetch complete - all CVEs processed")
                    break

                # Rate limiting
                if not api_key:
                    await asyncio.sleep(6)
                else:
                    await asyncio.sleep(0.6)

            if page_count >= max_pages:
                logger.warning(
                    "NVD fetch stopped at page limit (%d pages, %d CVEs processed)",
                    max_pages,
                    vulnerabilities_processed,
                )

        except httpx.HTTPError as e:
            raise CveRefreshError(f"HTTP error fetching NVD data: {e}") from e

        return {
            "vulnerabilities_processed": vulnerabilities_processed,
            "packages_processed": packages_processed,
            "source": "nvd",
        }

    async def fetch_ubuntu_data(self, db: Session) -> Dict[str, Any]:
        """
        Fetch CVE data from Ubuntu Security API.

        Args:
            db: Database session

        Returns:
            Dictionary with fetch results
        """
        client = await self._get_http_client()
        base_url = CVE_SOURCES["ubuntu"]["base_url"]
        vulnerabilities_processed = 0
        packages_processed = 0

        try:
            page_limit = 20
            max_pages = 100
            offset = 0

            for page in range(max_pages):
                params = {"limit": page_limit, "offset": offset}
                logger.info("Ubuntu fetch page %d, offset=%d", page + 1, offset)

                response = await client.get(base_url, params=params)
                response.raise_for_status()
                data = response.json()

                cves = data.get("cves", [])
                if not cves:
                    logger.info("Ubuntu fetch complete - no more CVEs")
                    break

                for cve_item in cves:
                    cve_id = cve_item.get("id")
                    if not cve_id:
                        continue

                    description = cve_item.get("description", "")
                    # Ubuntu API uses "priority" field
                    priority = cve_item.get("priority", "unknown")
                    severity = self.ubuntu_priority_to_severity(priority)

                    vuln = (
                        db.query(Vulnerability)
                        .filter(Vulnerability.cve_id == cve_id)
                        .first()
                    )
                    if not vuln:
                        vuln = Vulnerability(
                            cve_id=cve_id,
                            description=description,
                            severity=severity,
                        )
                        db.add(vuln)
                        db.flush()
                        vulnerabilities_processed += 1

                    # Ubuntu API returns packages as a list of objects
                    packages = cve_item.get("packages", [])
                    for pkg_info in packages:
                        pkg_name = pkg_info.get("name")
                        if not pkg_name:
                            continue

                        # Statuses is a list of status objects
                        statuses = pkg_info.get("statuses", [])
                        for status in statuses:
                            if status.get("status") == "released":
                                fixed_version = status.get("description", "")

                                existing = (
                                    db.query(PackageVulnerability)
                                    .filter(
                                        PackageVulnerability.vulnerability_id
                                        == vuln.id,
                                        PackageVulnerability.package_name == pkg_name,
                                        PackageVulnerability.package_manager == "apt",
                                        PackageVulnerability.source == "ubuntu",
                                    )
                                    .first()
                                )

                                if not existing:
                                    pkg_vuln = PackageVulnerability(
                                        vulnerability_id=vuln.id,
                                        package_name=pkg_name,
                                        package_manager="apt",
                                        fixed_version=fixed_version,
                                        source="ubuntu",
                                        advisory_ids=[],
                                    )
                                    db.add(pkg_vuln)
                                    packages_processed += 1

                db.commit()

                total_results = data.get("total_results", 0)
                offset += len(cves)
                if offset >= total_results or offset >= 2000:
                    logger.info(
                        "Ubuntu fetch complete: %d/%d CVEs processed",
                        offset,
                        total_results,
                    )
                    break

                await asyncio.sleep(0.5)

        except httpx.HTTPError as e:
            raise CveRefreshError(f"HTTP error fetching Ubuntu data: {e}") from e

        return {
            "vulnerabilities_processed": vulnerabilities_processed,
            "packages_processed": packages_processed,
            "source": "ubuntu",
        }

    def _process_debian_data_sync(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process Debian CVE data synchronously in a background thread.

        Args:
            data: Parsed JSON data from Debian Security Tracker

        Returns:
            Dictionary with processing results
        """
        session_factory = sessionmaker(bind=db_module.get_engine())
        thread_db = session_factory()
        vulnerabilities_processed = 0
        packages_processed = 0

        try:
            for pkg_name, pkg_data in data.items():
                for cve_id, cve_info in pkg_data.items():
                    if not cve_id.startswith("CVE-"):
                        continue

                    urgency = cve_info.get("urgency", "unimportant")
                    severity = self.debian_urgency_to_severity(urgency)
                    description = cve_info.get("description", "")

                    vuln = (
                        thread_db.query(Vulnerability)
                        .filter(Vulnerability.cve_id == cve_id)
                        .first()
                    )
                    if not vuln:
                        vuln = Vulnerability(
                            cve_id=cve_id,
                            description=description,
                            severity=severity,
                        )
                        thread_db.add(vuln)
                        thread_db.flush()
                        vulnerabilities_processed += 1

                    releases = cve_info.get("releases", {})
                    for release, release_info in releases.items():
                        fixed_version = release_info.get("fixed_version")
                        if fixed_version:
                            existing = (
                                thread_db.query(PackageVulnerability)
                                .filter(
                                    PackageVulnerability.vulnerability_id == vuln.id,
                                    PackageVulnerability.package_name == pkg_name,
                                    PackageVulnerability.package_manager == "apt",
                                    PackageVulnerability.source == "debian",
                                )
                                .first()
                            )

                            if not existing:
                                pkg_vuln = PackageVulnerability(
                                    vulnerability_id=vuln.id,
                                    package_name=pkg_name,
                                    package_manager="apt",
                                    fixed_version=fixed_version,
                                    source="debian",
                                )
                                thread_db.add(pkg_vuln)
                                packages_processed += 1

            thread_db.commit()
        finally:
            thread_db.close()

        return {
            "vulnerabilities_processed": vulnerabilities_processed,
            "packages_processed": packages_processed,
            "source": "debian",
        }

    async def fetch_debian_data(self, _db: Session) -> Dict[str, Any]:
        """
        Fetch CVE data from Debian Security Tracker.

        Args:
            _db: Database session (unused - thread creates its own session)

        Returns:
            Dictionary with fetch results
        """
        client = await self._get_http_client()
        base_url = CVE_SOURCES["debian"]["base_url"]

        try:
            response = await client.get(base_url)
            response.raise_for_status()
            data = response.json()

            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None, self._process_debian_data_sync, data
            )
            return result

        except httpx.HTTPError as e:
            raise CveRefreshError(f"HTTP error fetching Debian data: {e}") from e

    async def fetch_redhat_data(self, db: Session) -> Dict[str, Any]:
        """
        Fetch CVE data from Red Hat Security Data API.

        Args:
            db: Database session

        Returns:
            Dictionary with fetch results
        """
        client = await self._get_http_client()
        base_url = CVE_SOURCES["redhat"]["base_url"]
        vulnerabilities_processed = 0
        packages_processed = 0

        try:
            end_date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
            start_date = (datetime.now(timezone.utc) - timedelta(days=30)).strftime(
                "%Y-%m-%d"
            )

            params = {
                "after": start_date,
                "before": end_date,
                "per_page": 1000,
            }

            response = await client.get(base_url, params=params)
            response.raise_for_status()
            cves = response.json()

            for cve_item in cves:
                cve_id = cve_item.get("CVE")
                if not cve_id:
                    continue

                raw_severity = cve_item.get("severity")
                severity = raw_severity.upper() if raw_severity else "NONE"
                if severity not in ["CRITICAL", "HIGH", "MEDIUM", "LOW"]:
                    severity = "NONE"
                cvss_score = str(cve_item.get("cvss3_score", ""))
                public_date = cve_item.get("public_date")
                published_date = None
                if public_date:
                    try:
                        published_date = datetime.fromisoformat(
                            public_date.replace("Z", UTC_TIMEZONE_OFFSET)
                        ).replace(tzinfo=None)
                    except ValueError:
                        pass

                vuln = (
                    db.query(Vulnerability)
                    .filter(Vulnerability.cve_id == cve_id)
                    .first()
                )
                if not vuln:
                    vuln = Vulnerability(
                        cve_id=cve_id,
                        cvss_score=cvss_score,
                        cvss_version="3.1" if cvss_score else None,
                        severity=severity,
                        published_date=published_date,
                    )
                    db.add(vuln)
                    db.flush()
                    vulnerabilities_processed += 1

                affected_packages = cve_item.get("affected_packages", [])
                for pkg in affected_packages:
                    existing = (
                        db.query(PackageVulnerability)
                        .filter(
                            PackageVulnerability.vulnerability_id == vuln.id,
                            PackageVulnerability.package_name == pkg,
                            PackageVulnerability.package_manager == "dnf",
                            PackageVulnerability.source == "redhat",
                        )
                        .first()
                    )

                    if not existing:
                        pkg_vuln = PackageVulnerability(
                            vulnerability_id=vuln.id,
                            package_name=pkg,
                            package_manager="dnf",
                            source="redhat",
                        )
                        db.add(pkg_vuln)
                        packages_processed += 1

            db.commit()

        except httpx.HTTPError as e:
            raise CveRefreshError(f"HTTP error fetching Red Hat data: {e}") from e

        return {
            "vulnerabilities_processed": vulnerabilities_processed,
            "packages_processed": packages_processed,
            "source": "redhat",
        }

    async def fetch_microsoft_data(self, db: Session) -> Dict[str, Any]:
        """
        Fetch CVE data from Microsoft Security Response Center (MSRC).

        Args:
            db: Database session

        Returns:
            Dictionary with fetch results
        """
        client = await self._get_http_client()
        base_url = CVE_SOURCES["microsoft"]["base_url"]
        vulnerabilities_processed = 0
        packages_processed = 0

        # NOSONAR - These are XML namespace URIs (identifiers), not HTTP connections.
        # XML namespaces use http:// URIs as standard identifiers per W3C spec.
        namespaces = {
            "cvrf": "http://docs.oasis-open.org/csaf/ns/csaf-cvrf/v1.2/cvrf",  # NOSONAR
            "vuln": "http://docs.oasis-open.org/csaf/ns/csaf-cvrf/v1.2/vuln",  # NOSONAR
            "prod": "http://docs.oasis-open.org/csaf/ns/csaf-cvrf/v1.2/prod",  # NOSONAR
        }

        try:
            response = await client.get(f"{base_url}/updates")
            response.raise_for_status()
            updates_data = response.json()

            updates = updates_data.get("value", [])
            if not updates:
                logger.warning("No Microsoft security updates found")
                return {
                    "vulnerabilities_processed": 0,
                    "packages_processed": 0,
                    "source": "microsoft",
                }

            recent_updates = sorted(
                updates,
                key=lambda x: x.get("CurrentReleaseDate", ""),
                reverse=True,
            )[:3]

            for update in recent_updates:
                update_id = update.get("ID", "")
                cvrf_url = update.get("CvrfUrl", "")

                if not cvrf_url:
                    continue

                logger.info("Fetching Microsoft CVRF: %s", update_id)

                try:
                    cvrf_response = await client.get(cvrf_url)
                    cvrf_response.raise_for_status()
                    cvrf_xml = cvrf_response.text

                    # nosec B314 - using defusedxml for safe XML parsing
                    root = ET.fromstring(cvrf_xml)

                    for vuln_elem in root.findall(".//vuln:Vulnerability", namespaces):
                        cve_elem = vuln_elem.find("vuln:CVE", namespaces)
                        if cve_elem is None or not cve_elem.text:
                            continue

                        cve_id = cve_elem.text.strip()

                        title_elem = vuln_elem.find("vuln:Title", namespaces)
                        title = title_elem.text if title_elem is not None else ""

                        description = title
                        for note in vuln_elem.findall(
                            "vuln:Notes/vuln:Note", namespaces
                        ):
                            note_type = note.get("Type", "")
                            if note_type == "Description" and note.text:
                                description = note.text
                                break

                        cvss_score = None
                        severity = "NONE"

                        for score_set in vuln_elem.findall(
                            ".//vuln:CVSSScoreSets/vuln:ScoreSetV3", namespaces
                        ):
                            base_score_elem = score_set.find(
                                "vuln:BaseScore", namespaces
                            )
                            if base_score_elem is not None and base_score_elem.text:
                                try:
                                    cvss_score = base_score_elem.text.strip()
                                    score_val = float(cvss_score)
                                    severity = self.cvss3_to_severity(score_val)
                                except ValueError:
                                    pass
                                break

                        vuln = (
                            db.query(Vulnerability)
                            .filter(Vulnerability.cve_id == cve_id)
                            .first()
                        )

                        if not vuln:
                            vuln = Vulnerability(
                                cve_id=cve_id,
                                description=description[:4000] if description else None,
                                cvss_score=cvss_score,
                                cvss_version="3.1" if cvss_score else None,
                                severity=severity,
                            )
                            db.add(vuln)
                            db.flush()
                            vulnerabilities_processed += 1

                        for product_status in vuln_elem.findall(
                            ".//vuln:ProductStatuses/vuln:Status", namespaces
                        ):
                            status_type = product_status.get("Type", "")
                            if status_type == "Known Affected":
                                for product_id in product_status.findall(
                                    "vuln:ProductID", namespaces
                                ):
                                    if product_id.text:
                                        product_name = product_id.text.strip()

                                        existing = (
                                            db.query(PackageVulnerability)
                                            .filter(
                                                PackageVulnerability.vulnerability_id
                                                == vuln.id,
                                                PackageVulnerability.package_name
                                                == product_name,
                                                PackageVulnerability.source
                                                == "microsoft",
                                            )
                                            .first()
                                        )

                                        if not existing:
                                            pkg_vuln = PackageVulnerability(
                                                vulnerability_id=vuln.id,
                                                package_name=product_name,
                                                package_manager="windows",
                                                source="microsoft",
                                            )
                                            db.add(pkg_vuln)
                                            packages_processed += 1

                    db.commit()

                except ET.ParseError as e:
                    logger.warning(
                        "Failed to parse Microsoft CVRF %s: %s", update_id, e
                    )
                    continue
                except httpx.HTTPError as e:
                    logger.warning(
                        "Failed to fetch Microsoft CVRF %s: %s", update_id, e
                    )
                    continue

                await asyncio.sleep(1)

        except httpx.HTTPError as e:
            raise CveRefreshError(f"HTTP error fetching Microsoft data: {e}") from e

        return {
            "vulnerabilities_processed": vulnerabilities_processed,
            "packages_processed": packages_processed,
            "source": "microsoft",
        }

    async def fetch_freebsd_data(self, _db: Session) -> Dict[str, Any]:
        """
        Fetch CVE data from FreeBSD VuXML.

        Args:
            _db: Database session (unused - not yet implemented)

        Returns:
            Dictionary with fetch results
        """
        logger.info("FreeBSD VuXML source not yet implemented")
        return {
            "vulnerabilities_processed": 0,
            "packages_processed": 0,
            "source": "freebsd",
            "details": {"message": "FreeBSD VuXML parsing not yet implemented"},
        }
